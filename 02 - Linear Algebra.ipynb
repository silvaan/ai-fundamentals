{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d21c59",
   "metadata": {},
   "source": [
    "# Fundamentos de Álgebra Linear com PyTorch\n",
    "\n",
    "Este notebook serve como uma introdução aos conceitos fundamentais da Álgebra Linear, a matemática dos dados. A compreensão profunda destes conceitos é um pré-requisito para o estudo avançado de qualquer campo da Inteligência Artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5fa49",
   "metadata": {},
   "source": [
    "## 1. Escalares, Vetores, Matrizes e Tensores\n",
    "\n",
    "A Álgebra Linear lida fundamentalmente com vetores. No entanto, é útil começar com as estruturas que os englobam.\n",
    "\n",
    "-   **Escalar**: Um único número, como $x \\in \\mathbb{R}$.\n",
    "-   **Vetor**: Um array de números ordenados. Um vetor $v \\in \\mathbb{R}^n$ possui $n$ componentes, $v = [v_1, v_2, ..., v_n]$. Geralmente, nos referimos a ele como um vetor coluna:\n",
    "$$ v = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} $$\n",
    "-   **Matriz**: Um array bidimensional de números. Uma matriz $A \\in \\mathbb{R}^{m \\times n}$ tem $m$ linhas e $n$ colunas.\n",
    "$$ A = \\begin{bmatrix}\n",
    "A_{1,1} & A_{1,2} & \\cdots & A_{1,n} \\\\\n",
    "A_{2,1} & A_{2,2} & \\cdots & A_{2,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "A_{m,1} & A_{m,2} & \\cdots & A_{m,n}\n",
    "\\end{bmatrix} $$\n",
    "-   **Tensor**: É uma generalização de um escalar (tensor de ordem 0), um vetor (tensor de ordem 1) e uma matriz (tensor de ordem 2) para um número arbitrário de dimensões (ordem $d$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Verificando a versão do PyTorch\n",
    "print(f\"Versão do PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar (Tensor de ordem 0)\n",
    "escalar = torch.tensor(3.14)\n",
    "print(\"Escalar:\")\n",
    "print(escalar)\n",
    "print(\"Ordem (ndim):\", escalar.ndim)\n",
    "print(\"Shape:\", escalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d00a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetor (Tensor de ordem 1)\n",
    "vetor = torch.tensor([1, 2, 3])\n",
    "print(\"Vetor:\")\n",
    "print(vetor)\n",
    "print(\"Ordem (ndim):\", vetor.ndim)\n",
    "print(\"Shape:\", vetor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz (Tensor de ordem 2)\n",
    "matriz = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(\"Matriz:\")\n",
    "print(matriz)\n",
    "print(\"Ordem (ndim):\", matriz.ndim)\n",
    "print(\"Shape:\", matriz.shape) # 3 linhas, 2 colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf29e01",
   "metadata": {},
   "source": [
    "## 2. Criação e Manipulação de Tensores em PyTorch\n",
    "\n",
    "Embora possamos criar tensores a partir de listas Python, PyTorch oferece funções otimizadas para criar tensores comumente utilizados e para manipular seu formato.\n",
    "\n",
    "### Funções de Criação\n",
    "- `torch.ones(shape)`: Cria um tensor preenchido com o valor 1.\n",
    "- `torch.zeros(shape)`: Cria um tensor preenchido com o valor 0.\n",
    "- `torch.rand(shape)`: Cria um tensor com valores aleatórios de uma distribuição uniforme em $[0, 1)$.\n",
    "- `torch.randn(shape)`: Cria um tensor com valores aleatórios de uma distribuição normal padrão (média 0, variância 1).\n",
    "- `torch.arange(start, end, step)`: Cria um tensor com valores em um intervalo.\n",
    "- `torch.linspace(start, end, steps)`: Cria um tensor com um número específico de valores (`steps`) espaçados linearmente entre `start` e `end`.\n",
    "\n",
    "### Manipulação de Formato\n",
    "- `.shape`: Atributo que retorna a dimensionalidade do tensor.\n",
    "- `.reshape(new_shape)` / `.view(new_shape)`: Remodelam o tensor para um novo formato. `view` é mais rápido, mas só funciona em tensores contíguos na memória. `reshape` é mais flexível.\n",
    "- `.flatten()`: Transforma um tensor multidimensional em um tensor 1D (um vetor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff88907",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "print(\"Tensor de Zeros (2, 3):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f58583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, 2)\n",
    "print(\"Tensor de Uns (3, 2):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 5)\n",
    "print(\"Tensor com arange(0, 5):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c111843",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 5)\n",
    "print(\"Tensor com linspace(0, 1, 5 passos):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e51764",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(\"Tensor Rand (dist. uniforme):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 2)\n",
    "print(\"Tensor Randn (dist. normal):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0da97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de formato\n",
    "x = torch.arange(12)\n",
    "print(\"--- Manipulação de Formato ---\")\n",
    "print(\"\\nTensor original (x):\\n\", x)\n",
    "print(\"Shape de x:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89456b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "x_reshaped = x.reshape(3, 4)\n",
    "print(\"x com reshape(3, 4):\\n\", x_reshaped)\n",
    "print(\"Shape de x_reshaped:\", x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e84c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "x_flattened = x_reshaped.flatten()\n",
    "print(\"x_reshaped achatado (flatten):\\n\", x_flattened)\n",
    "print(\"Shape de x_flattened:\", x_flattened.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef029f",
   "metadata": {},
   "source": [
    "### Exercícios: Criação e Manipulação de Tensores\n",
    "\n",
    "1.  **Tensor Aleatório**: Crie um tensor de formato `(5, 5)` com números aleatórios provenientes de uma distribuição normal padrão.\n",
    "2.  **Sequência Linear**: Crie um vetor (tensor 1D) que comece em -10, termine em 10 e contenha exatamente 50 pontos.\n",
    "3.  **Remodelagem**: Crie um vetor com 100 elementos usando `torch.arange`. Em seguida, remodele-o para que tenha o formato `(10, 10)`.\n",
    "4.  **Achatamento para Redes Neurais**: Crie um tensor que simule um lote (batch) de 4 imagens em escala de cinza de tamanho 28x28 (formato `(4, 28, 28)`). Em seguida, \"achate\" cada imagem para que o tensor final tenha o formato `(4, 784)`, que é um formato comum para a entrada de uma camada densa (fully-connected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82081987",
   "metadata": {},
   "source": [
    "## 3. Indexação e Fatiamento\n",
    "\n",
    "Acessar e modificar subconjuntos de um tensor é uma operação rotineira. A sintaxe em PyTorch é similar à do NumPy, utilizando colchetes `[]` e o operador de fatiamento `:` (dois pontos). A indexação começa em zero.\n",
    "\n",
    "-   Acessar um elemento: `T[i, j]` para o elemento na linha `i` e coluna `j`.\n",
    "-   Acessar uma linha: `T[i, :]` para a linha `i` inteira.\n",
    "-   Acessar uma coluna: `T[:, j]` para a coluna `j` inteira.\n",
    "-   Acessar um subconjunto: `T[start_row:end_row, start_col:end_col]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7667f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um tensor 2D para os exemplos\n",
    "T = torch.arange(20).reshape(5, 4)\n",
    "\n",
    "print(\"Tensor original (5x4):\\n\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando a linha de índice 1\n",
    "T_linha_1 = T[1, :]\n",
    "print(\"Linha de índice 1 (T[1, :]):\\n\", T_linha_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando a coluna de índice 2\n",
    "T_coluna_2 = T[:, 2]\n",
    "print(\"Coluna de índice 2 (T[:, 2]):\\n\", T_coluna_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606324ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando o elemento na linha 3, coluna 1\n",
    "T_el = T[3, 1]\n",
    "print(\"Elemento em (3, 1):\", T_el.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e58c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fatiando para obter um sub-bloco (linhas 1 e 2, colunas 0 e 1)\n",
    "sub_bloco = T[1:3, 0:2]\n",
    "print(\"Sub-bloco T[1:3, 0:2]:\\n\", sub_bloco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e18866",
   "metadata": {},
   "source": [
    "### Exercícios: Indexação e Fatiamento\n",
    "\n",
    "Use o tensor abaixo para resolver os exercícios:\n",
    "`T = torch.arange(25).reshape(5, 5)`\n",
    "\n",
    "1.  **Seleção Simples**: Selecione e imprima o número `13` do tensor `T`.\n",
    "2.  **Linha Inteira**: Selecione e imprima a terceira linha inteira (a que contém os elementos 10, 11, 12, 13, 14).\n",
    "3.  **Sub-bloco Central**: Selecione e imprima o sub-bloco 3x3 que fica no centro da matriz `T`. O resultado deve ser:\n",
    "    ```\n",
    "    tensor([[ 6,  7,  8],\n",
    "            [11, 12, 13],\n",
    "            [16, 17, 18]])\n",
    "    ```\n",
    "4.  **Padrão Xadrez (Desafio)**: Selecione todos os elementos nas \"casas pares\" da matriz (e.g., T[0,0], T[0,2], T[0,4], T[2,0], etc.).\n",
    "5.  **Modificação por Fatiamento**: Usando fatiamento, substitua o sub-bloco central 3x3 (o mesmo do exercício 3) por uma matriz de zeros do mesmo tamanho. Imprima o tensor `T` modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd3147",
   "metadata": {},
   "source": [
    "## 4. Redução de Tensores\n",
    "\n",
    "Operações de redução agregam todos os valores de um tensor (ou de uma de suas dimensões) em um único valor, como soma, média, produto, etc.\n",
    "\n",
    "- `torch.sum()`: Soma dos elementos.\n",
    "- `torch.mean()`: Média dos elementos.\n",
    "- `torch.prod()`: Produto dos elementos.\n",
    "- `torch.max()` / `torch.min()`: Valores máximo e mínimo.\n",
    "\n",
    "O argumento `dim` especifica a dimensão ao longo da qual a operação é aplicada.\n",
    "- `dim=0`: Reduz ao longo das linhas (resultando em um valor por coluna).\n",
    "- `dim=1`: Reduz ao longo das colunas (resultando em um valor por linha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.arange(1, 7, dtype=torch.float32).reshape(2, 3)\n",
    "print(\"Tensor original:\\n\", T)\n",
    "\n",
    "# Redução total\n",
    "print(\"\\nSoma total (sum):\", T.sum().item())\n",
    "print(\"Média total (mean):\", T.mean().item())\n",
    "\n",
    "# Redução por dimensão\n",
    "soma_colunas = T.sum(dim=0)\n",
    "print(\"\\nSoma ao longo das linhas (dim=0):\", soma_colunas)\n",
    "\n",
    "soma_linhas = T.sum(dim=1)\n",
    "print(\"Soma ao longo das colunas (dim=1):\", soma_linhas)\n",
    "\n",
    "max_vals, max_indices = T.max(dim=1)\n",
    "print(\"\\nValores máximos por linha (dim=1):\", max_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021e057",
   "metadata": {},
   "source": [
    "### Exercícios: Redução de Tensores\n",
    "\n",
    "Crie um tensor aleatório de formato `(4, 6)` para os exercícios a seguir.\n",
    "`dados = torch.rand(4, 6)`\n",
    "\n",
    "1.  **Média Geral**: Calcule a média de todos os elementos no tensor `dados`.\n",
    "2.  **Soma por Coluna**: Calcule a soma de cada coluna. O resultado deve ser um vetor com 6 elementos.\n",
    "3.  **Valor Mínimo por Linha**: Encontre o valor mínimo de cada linha. O resultado deve ser um vetor com 4 elementos.\n",
    "4.  **Desvio Padrão**: Calcule o desvio padrão de cada coluna do tensor. (Dica: use `torch.std`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ead54",
   "metadata": {},
   "source": [
    "## 5. Operações com Vetores\n",
    "\n",
    "As operações mais básicas em Álgebra Linear são a adição de vetores e a multiplicação por escalar.\n",
    "\n",
    "### Adição de Vetores\n",
    "A soma de dois vetores $u, v \\in \\mathbb{R}^n$ é realizada elemento a elemento:\n",
    "$$ w = u + v \\quad \\text{onde} \\quad w_i = u_i + v_i $$\n",
    "\n",
    "### Multiplicação por Escalar\n",
    "A multiplicação de um vetor $v \\in \\mathbb{R}^n$ por um escalar $c \\in \\mathbb{R}$ resulta em um novo vetor onde cada elemento é multiplicado por $c$:\n",
    "$$ w = c v \\quad \\text{onde} \\quad w_i = c \\cdot v_i $$\n",
    "Geometricamente, isso \"escala\" (estica ou encolhe) o vetor $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de Vetores\n",
    "u = torch.tensor([1, 2, 3])\n",
    "v = torch.tensor([10, 20, 30])\n",
    "soma_vetores = u + v\n",
    "print(\"Adição de Vetores (u + v):\")\n",
    "print(soma_vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicação por Escalar\n",
    "c = 2\n",
    "w = c * u\n",
    "print(f\"Multiplicação por Escalar ({c} * u):\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f891a80",
   "metadata": {},
   "source": [
    "### Exercícios: Operações com Vetores\n",
    "\n",
    "Considere os vetores  \n",
    "$u = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix}, \\quad v = \\begin{bmatrix}3 \\\\ -1\\end{bmatrix}$  \n",
    "\n",
    "1. **Adição e Subtração**: Calcule $u + v$ e $u - v$\n",
    "\n",
    "2. **Multiplicação por Escalar**: Calcule $3u$\n",
    "\n",
    "3. **Combinação Linear**: Calcule o vetor $w = 2u + 0.5v$ \n",
    "\n",
    "4. **Interpretação Geométrica (Teórico)**: Sem calcular, apenas descreva geometricamente, qual seria a relação entre o vetor $u$ e o vetor $z = -u$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfa975",
   "metadata": {},
   "source": [
    "## 6. Norma de um Vetor\n",
    "\n",
    "A norma de um vetor é uma medida do seu \"comprimento\" ou \"magnitude\". A norma mais comum é a norma Euclidiana, ou norma $\\ell_2$. Para um vetor $v \\in \\mathbb{R}^n$, a norma $\\ell_2$, denotada por $||v||_2$, é calculada como:\n",
    "\n",
    "$$ ||v||_2 = \\sqrt{\\sum_{i=1}^{n} v_i^2} = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2} $$\n",
    "\n",
    "A norma de um vetor é sempre um valor não-negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([3.0, 4.0])\n",
    "\n",
    "# Calculando a norma l2\n",
    "# sqrt(3^2 + 4^2) = sqrt(9 + 16) = sqrt(25) = 5\n",
    "norma_v = torch.linalg.norm(v)\n",
    "\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Norma l2 de v:\", norma_v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetor unitário: um vetor com norma igual a 1\n",
    "# Para obter um vetor unitário, dividimos o vetor pela sua norma\n",
    "v_unitario = v / norma_v\n",
    "print(\"Vetor unitário de v:\", v_unitario)\n",
    "print(\"Norma do vetor unitário:\", torch.linalg.norm(v_unitario).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9390c8",
   "metadata": {},
   "source": [
    "### Exercícios: Norma de um Vetor\n",
    "\n",
    "1. **Cálculo de Norma $\\ell_2$**: Calcule a norma Euclidiana ($\\ell_2$) do vetor $v = \\begin{bmatrix}5 \\\\ 12\\end{bmatrix}$. O resultado deve ser um número inteiro.  \n",
    "\n",
    "2. **Cálculo de Norma $\\ell_1$**: A norma $\\ell_1$ (ou norma de Manhattan) é a soma dos valores absolutos dos componentes do vetor:  \n",
    "   $||v||_1 = \\sum_{i=1}^{n} |v_i|$  \n",
    "   Calcule a norma $\\ell_1$ do mesmo vetor $v$ do exercício 1.  \n",
    "\n",
    "3. **Vetor Unitário (Versor)**: Crie um vetor unitário (um vetor com norma $\\ell_2$ igual a 1) a partir do vetor $w = \\begin{bmatrix}1 \\\\ 2 \\\\ 3\\end{bmatrix}$. Para isso, divida o vetor $w$ pela sua norma.  \n",
    "\n",
    "4. **Verificação**: Verifique que o vetor que você criou no exercício 3 realmente tem norma igual a 1. (Pode haver um erro mínimo de ponto flutuante, e.g., 0.999999).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0797715",
   "metadata": {},
   "source": [
    "## 7. Produto Interno e Ângulo entre Vetores\n",
    "\n",
    "O produto interno (ou produto escalar, *dot product*) de dois vetores $u, v \\in \\mathbb{R}^n$ é a soma dos produtos dos elementos correspondentes:\n",
    "\n",
    "$$ u^T v = u \\cdot v = \\sum_{i=1}^{n} u_i v_i $$\n",
    "\n",
    "Ele possui uma propriedade geométrica fundamental que o relaciona ao ângulo $\\theta$ entre os vetores:\n",
    "\n",
    "$$ u \\cdot v = ||u||_2 \\ ||v||_2 \\ \\cos(\\theta) $$\n",
    "\n",
    "Podemos usar esta relação para encontrar o ângulo entre os vetores. Rearranjando a equação, temos:\n",
    "\n",
    "$$ \\cos(\\theta) = \\frac{u \\cdot v}{||u||_2 \\ ||v||_2} $$\n",
    "\n",
    "E, finalmente, o ângulo $\\theta$ é obtido pela função arco cosseno:\n",
    "\n",
    "$$ \\theta = \\arccos\\left(\\frac{u \\cdot v}{||u||_2 \\ ||v||_2}\\right) $$\n",
    "\n",
    "Um produto interno de zero indica que os vetores são ortogonais ($\\theta=90^\\circ$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad407b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1, 2, 3])\n",
    "v = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Calculando o produto interno\n",
    "# 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n",
    "produto_interno = torch.dot(u, v)\n",
    "\n",
    "print(\"Vetor u:\", u)\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Produto Interno (u . v):\", produto_interno.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0170f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1., 2.])\n",
    "v = torch.tensor([3., 1.])\n",
    "\n",
    "# 1. Calcular o produto interno\n",
    "produto_interno = torch.dot(u, v)\n",
    "\n",
    "# 2. Calcular a norma de cada vetor\n",
    "norma_u = torch.linalg.norm(u)\n",
    "norma_v = torch.linalg.norm(v)\n",
    "\n",
    "# 3. Calcular o cosseno do ângulo\n",
    "cos_theta = produto_interno / (norma_u * norma_v)\n",
    "\n",
    "# 4. Calcular o ângulo em radianos usando arccos\n",
    "theta_rad = torch.acos(cos_theta)\n",
    "\n",
    "# Converter para graus\n",
    "theta_deg = theta_rad * 180.0 / torch.pi\n",
    "\n",
    "print(f\"Cosseno do ângulo: {cos_theta.item():.2f}\")\n",
    "print(f\"Ângulo em radianos: {theta_rad.item():.2f}\")\n",
    "print(f\"Ângulo em graus: {theta_deg:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de vetores ortogonais\n",
    "u_ort = torch.tensor([1., 0.])\n",
    "v_ort = torch.tensor([0., 1.])\n",
    "print(\"Produto Interno de vetores ortogonais:\", torch.dot(u_ort, v_ort).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0203a",
   "metadata": {},
   "source": [
    "### Exercícios: Produto Interno e Ângulo\n",
    "\n",
    "1. **Ortogonalidade**: Considere os vetores $u = \\begin{bmatrix}2 \\\\ -1 \\\\ 1\\end{bmatrix}$ e $v = \\begin{bmatrix}1 \\\\ 2 \\\\ 0\\end{bmatrix}$. Calcule o produto interno entre eles. Eles são ortogonais? Justifique.  \n",
    "\n",
    "2. **Projeção**: O produto interno pode ser usado para calcular a projeção de um vetor sobre o outro. A projeção escalar de $u$ sobre $v$ é dada por  \n",
    "   $\\dfrac{u \\cdot v}{||v||_2}$  \n",
    "   Calcule essa projeção para os vetores do exercício anterior.  \n",
    "\n",
    "3. **Ângulo Geométrico**: Crie dois vetores 2D quaisquer e calcule o ângulo (em graus) entre eles. Lembre que o ângulo pode ser obtido por  \n",
    "   $\\theta = \\cos^{-1}\\left(\\dfrac{u \\cdot v}{||u||_2 \\, ||v||_2}\\right)$.  \n",
    "   Teste com vetores em que você já saiba o ângulo (ex: $[1,0]$ e $[0,1]$ devem dar $90^\\circ$, $[1,0]$ e $[1,1]$ devem dar $45^\\circ$).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d50af",
   "metadata": {},
   "source": [
    "## 8. Multiplicação de Matriz por Vetor\n",
    "\n",
    "A multiplicação de uma matriz $A \\in \\mathbb{R}^{m \\times n}$ por um vetor $v \\in \\mathbb{R}^n$ resulta em um novo vetor $b \\in \\mathbb{R}^m$. Essa operação representa uma **transformação linear**.\n",
    "\n",
    "Pense na matriz $A$ como uma função que \"transforma\" o vetor $v$, que vive no espaço $\\mathbb{R}^n$ (o espaço de entrada), e o mapeia para um novo vetor $b=Av$, que vive no espaço $\\mathbb{R}^m$ (o espaço de saída). Essa transformação pode rotacionar, escalar ou cisalhar (shear) o vetor original.\n",
    "\n",
    "O mecanismo desta transformação é que o vetor resultante $b$ é uma **combinação linear das colunas da matriz $A$**, onde os pesos dessa combinação são exatamente os **elementos do vetor $v$**:\n",
    "\n",
    "$$ b = A v = v_1 \\begin{bmatrix} A_{1,1} \\\\ \\vdots \\\\ A_{m,1} \\end{bmatrix} + v_2 \\begin{bmatrix} A_{1,2} \\\\ \\vdots \\\\ A_{m,2} \\end{bmatrix} + \\cdots + v_n \\begin{bmatrix} A_{1,n} \\\\ \\vdots \\\\ A_{m,n} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07411943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de transformação A (leva de R^2 para R^3)\n",
    "A = torch.tensor([[1, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 1]], dtype=torch.float32)\n",
    "\n",
    "# Vetor original no espaço R^2\n",
    "v = torch.tensor([2., 3.])\n",
    "\n",
    "# Aplicar a transformação: A @ v\n",
    "# O resultado será um novo vetor no espaço R^3\n",
    "b = A @ v\n",
    "\n",
    "print(\"Matriz de Transformação A (leva de R^2 para R^3):\\n\", A)\n",
    "print(\"\\nVetor original v (em R^2):\\n\", v)\n",
    "print(\"\\nVetor transformado b = A@v (em R^3):\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88869a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a intuição da combinação linear:\n",
    "# b = 2 * A[:,0] + 3 * A[:,1]\n",
    "b_combinacao_linear = v[0] * A[:, 0] + v[1] * A[:, 1]\n",
    "print(\"Resultado via combinação linear das colunas:\\n\", b_combinacao_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb5419",
   "metadata": {},
   "source": [
    "### Exercícios: Multiplicação de Matriz por Vetor\n",
    "\n",
    "1. **Transformação Simples**: Dada a matriz $A = \\begin{bmatrix}2 & 0 \\\\ 0 & 1\\end{bmatrix}$ e o vetor $v = \\begin{bmatrix}3 \\\\ 5\\end{bmatrix}$, calcule o produto $b = A v$. Como a matriz $A$ transformou o vetor $v$? (Observe o que aconteceu com cada componente de $v$).  \n",
    "\n",
    "2. **Rotação**: Uma matriz de rotação em 2D que gira um vetor em $\\theta$ graus no sentido anti-horário é dada por $R = \\begin{bmatrix}\\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta)\\end{bmatrix}$. Crie essa matriz $R$ para uma rotação de $90^\\circ$. Em seguida, aplique essa transformação ao vetor $v = \\begin{bmatrix}2 \\\\ 0\\end{bmatrix}$. Qual é o vetor resultante? O resultado faz sentido geometricamente?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para plotar as setas:\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ax.arrow(0, 0, v[0], v[1], head_width=0.05, color='blue', length_includes_head=True, label=\"v original\")\n",
    "# ax.arrow(0, 0, w[0], w[1], head_width=0.05, color='green', length_includes_head=True, label=\"A*v\")\n",
    "# plt.xlim(-.1, 1)\n",
    "# plt.ylim(-.1, 1)\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f829b5c",
   "metadata": {},
   "source": [
    "## 9. Multiplicação de Matrizes: Composição de Transformações\n",
    "\n",
    "Seguindo a mesma lógica, a multiplicação de duas matrizes, $C = AB$, representa a **composição de duas transformações lineares**.\n",
    "\n",
    "Se uma matriz $B \\in \\mathbb{R}^{n \\times p}$ transforma um vetor do espaço $\\mathbb{R}^p$ para $\\mathbb{R}^n$, e uma matriz $A \\in \\mathbb{R}^{m \\times n}$ transforma um vetor de $\\mathbb{R}^n$ para $\\mathbb{R}^m$, então a matriz produto $C \\in \\mathbb{R}^{m \\times p}$ representa a transformação única que leva diretamente do espaço $\\mathbb{R}^p$ para $\\mathbb{R}^m$.\n",
    "\n",
    "Em outras palavras, aplicar a transformação $C$ a um vetor $v$ é o mesmo que aplicar primeiro a transformação $B$ e depois aplicar a transformação $A$ ao resultado:\n",
    "\n",
    "$$ C v = (A B) v = A (B v) $$\n",
    "\n",
    "Cada elemento $C_{ij}$ da matriz resultante é o produto interno da $i$-ésima linha da matriz $A$ com a $j$-ésima coluna da matriz $B$.\n",
    "\n",
    "$$ C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]]) # Matriz 2x2\n",
    "B = torch.tensor([[10, 20], [30, 40]]) # Matriz 2x2\n",
    "\n",
    "# Usando torch.matmul ou o operador @\n",
    "C = torch.matmul(A, B)\n",
    "# C = A @ B\n",
    "\n",
    "print(\"Matriz A:\\n\", A)\n",
    "print(\"\\nMatriz B:\\n\", B)\n",
    "print(\"\\nResultado da multiplicação A @ B:\\n\", C)\n",
    "\n",
    "# Verificando a não-comutatividade\n",
    "print(\"\\nResultado da multiplicação B @ A:\\n\", B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa191ca3",
   "metadata": {},
   "source": [
    "### Exercícios: Multiplicação de Matrizes\n",
    "\n",
    "1.  **Compatibilidade**: Dadas as matrizes `A = torch.randn(4, 2)` e `B = torch.randn(2, 5)`, calcule o produto `C = A @ B`. Qual é o formato da matriz resultante? O produto `B @ A` é possível de ser calculado?\n",
    "2.  **Não Comutatividade**: Crie duas matrizes quadradas `X` e `Y` de formato `(3, 3)` com números aleatórios. Mostre que `X @ Y` não é igual a `Y @ X`.\n",
    "3.  **Matriz Identidade**: A matriz identidade `I` é o elemento neutro da multiplicação de matrizes ($AI = IA = A$). Crie uma matriz aleatória `A` de formato `(3, 3)` e uma matriz identidade `I` de mesmo formato (Dica: `torch.eye(3)`). Verifique que `A @ I` resulta na própria matriz `A`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e74b5",
   "metadata": {},
   "source": [
    "## 10. Distância entre Vetores\n",
    "\n",
    "A distância entre dois pontos (representados por vetores) no espaço Euclidiano é o comprimento do vetor que conecta esses dois pontos. A distância Euclidiana entre dois vetores $u, v \\in \\mathbb{R}^n$ é definida como a norma do vetor diferença $u-v$:\n",
    "\n",
    "$$ \\text{dist}(u, v) = ||u - v||_2 = \\sqrt{\\sum_{i=1}^{n} (u_i - v_i)^2} $$\n",
    "\n",
    "Este conceito é a base para muitos algoritmos de Machine Learning, como o k-Nearest Neighbors (k-NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1., 5.])\n",
    "v = torch.tensor([4., 1.])\n",
    "\n",
    "# Calculando o vetor diferença\n",
    "diferenca = u - v\n",
    "\n",
    "# Calculando a norma do vetor diferença\n",
    "distancia = torch.linalg.norm(diferenca)\n",
    "# sqrt((1-4)^2 + (5-1)^2) = sqrt((-3)^2 + 4^2) = sqrt(9 + 16) = sqrt(25) = 5\n",
    "\n",
    "print(\"Vetor u:\", u)\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Distância Euclidiana entre u e v:\", distancia.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch também tem uma função de conveniência para isso\n",
    "distancia_pdist = torch.cdist(u.unsqueeze(0), v.unsqueeze(0))\n",
    "print(\"Distância calculada com torch.cdist:\", distancia_pdist.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc7424",
   "metadata": {},
   "source": [
    "### Exercícios: Distância entre Vetores\n",
    "\n",
    "1.  **Distância Euclidiana**: Calcule a distância Euclidiana entre os pontos (vetores) `p1 = torch.tensor([2., 3.])` e `p2 = torch.tensor([5., 7.])`.\n",
    "2.  **Ponto mais Próximo**: Dados três pontos, `A = torch.tensor([0., 0.])`, `B = torch.tensor([10., 0.])` e `C = torch.tensor([4., 5.])`, qual dos pontos (A ou B) está mais próximo do ponto C?\n",
    "3.  **Impacto da Escala**: Calcule a distância entre `u = torch.tensor([1000., 1.])` e `v = torch.tensor([1001., 2.])`. Observe como a grande diferença na primeira dimensão domina completamente a distância total. Este é um dos motivos pelos quais a normalização de dados (vista nos exercícios de broadcasting) é tão importante em muitos algoritmos de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d286",
   "metadata": {},
   "source": [
    "## 11. Broadcasting: Operações Inteligentes entre Tensores\n",
    "\n",
    "Em muitas situações, desejamos realizar operações entre tensores que não possuem exatamente o mesmo formato. O caso mais simples é operar um escalar com um tensor (e.g., somar o número 5 a todos os elementos de uma matriz). Uma abordagem mais complexa seria somar um vetor a cada linha de uma matriz.\n",
    "\n",
    "Broadcasting é um mecanismo poderoso e eficiente que realiza essas operações sem a necessidade de criar cópias dos dados na memória. Ele define um conjunto de regras para tratar tensores de formatos diferentes. A operação é possível se, ao comparar os formatos dos tensores da direita para a esquerda (a partir da última dimensão), uma das duas condições for verdadeira para cada par de dimensões:\n",
    "\n",
    "1.  As dimensões são iguais.\n",
    "2.  Uma das dimensões é 1 (um escalar é tratado como se tivesse dimensões de tamanho 1).\n",
    "\n",
    "Se essas condições forem satisfeitas, o tensor com a dimensão menor é virtualmente \"esticado\" (broadcasted) para corresponder ao tamanho da dimensão do outro tensor.\n",
    "\n",
    "**Exemplo:** Somar um vetor de formato `(3,)` a uma matriz de formato `(2, 3)`.\n",
    "\n",
    "1.  Alinhamos os formatos pela direita:\n",
    "    - Matriz: `2, 3`\n",
    "    - Vetor: `   3`\n",
    "2.  Comparando a última dimensão: `3` e `3`. Elas são iguais. (OK)\n",
    "3.  Comparando a penúltima dimensão: `2` e (não existe). O PyTorch adiciona uma dimensão de tamanho 1 ao vetor:\n",
    "    - Matriz: `2, 3`\n",
    "    - Vetor:  `1, 3`\n",
    "4.  Agora, comparamos a primeira dimensão: `2` e `1`. Como uma delas é `1`, a condição é satisfeita. (OK)\n",
    "\n",
    "O vetor de formato `(1, 3)` é então \"esticado\" para o formato `(2, 3)` e a soma é realizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 0: Somando um escalar a um tensor (caso mais simples)\n",
    "matriz_base = torch.arange(6).reshape(2, 3)\n",
    "escalar = 100\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:   (2, 3)\n",
    "# Escalar:  () -> é \"esticado\" para o formato (2, 3)\n",
    "resultado_escalar = matriz_base + escalar\n",
    "\n",
    "print(\"--- Broadcasting de Escalar ---\")\n",
    "print(\"Matriz (2, 3):\\n\", matriz_base)\n",
    "print(\"\\nEscalar:\", escalar)\n",
    "print(\"\\nResultado (Matriz + Escalar):\\n\", resultado_escalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Somando um vetor-linha a uma matriz\n",
    "matriz = torch.ones((3, 4)) # Matriz 3x4\n",
    "vetor_linha = torch.arange(4, dtype=torch.float32) # Vetor 1x4\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:      (3, 4)\n",
    "# Vetor-linha:    (4,) -> alinhado como (1, 4)\n",
    "# O vetor é \"esticado\" para o formato (3, 4) e somado a cada linha\n",
    "resultado = matriz + vetor_linha\n",
    "\n",
    "print(\"--- Broadcasting de Vetor-Linha ---\")\n",
    "print(\"Matriz (3, 4):\\n\", matriz)\n",
    "print(\"\\nVetor-linha (4,):\\n\", vetor_linha)\n",
    "print(\"\\nResultado (Matriz + Vetor-linha):\\n\", resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52677db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Somando um vetor-coluna a uma matriz\n",
    "vetor_coluna = torch.arange(3, dtype=torch.float32).reshape(3, 1) # Vetor 3x1\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:       (3, 4)\n",
    "# Vetor-coluna: (3, 1)\n",
    "# O vetor-coluna é \"esticado\" nas colunas para o formato (3, 4)\n",
    "resultado_col = matriz + vetor_coluna\n",
    "\n",
    "print(\"--- Broadcasting de Vetor-Coluna ---\")\n",
    "print(\"Matriz (3, 4):\\n\", matriz)\n",
    "print(\"\\nVetor-coluna (3, 1):\\n\", vetor_coluna)\n",
    "print(\"\\nResultado (Matriz + Vetor-coluna):\\n\", resultado_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cc2ce",
   "metadata": {},
   "source": [
    "### Exercícios: Broadcasting\n",
    "\n",
    "1.  **Normalização Z-score (Standard Scaler)**: Um passo comum em pré-processamento de dados é subtrair a média e dividir pelo desvio padrão de cada característica (coluna).\n",
    "    - Crie uma matriz de dados \"falsos\" de formato `(10, 3)`.\n",
    "    - Calcule a média de cada coluna (o resultado será um vetor de formato `(3,)`).\n",
    "    - Calcule o desvio padrão de cada coluna (resultado também será `(3,)`).\n",
    "    - Usando broadcasting, subtraia o vetor de médias da matriz de dados.\n",
    "    - Usando broadcasting novamente, divida o resultado pelo vetor de desvios padrão.\n",
    "    O resultado é a sua matriz normalizada.\n",
    "2.  **Compatibilidade (Teórico)**: Sem usar código, diga se as operações de broadcasting a seguir são válidas. Se sim, qual o formato do tensor resultante?\n",
    "    - Tensor A `(5, 3)` + Tensor B `(1, 3)`\n",
    "    - Tensor A `(5, 3)` + Tensor B `(5, 1)`\n",
    "    - Tensor A `(5, 3)` + Tensor B `(3,)`\n",
    "    - Tensor A `(4, 1, 3)` + Tensor B `(4, 5, 3)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
